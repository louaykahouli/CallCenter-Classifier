{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18b9092",
   "metadata": {
    "id": "f18b9092"
   },
   "source": [
    "# Entra√Ænement du mod√®le de classification Call Center sur Google Colab\n",
    "\n",
    "Ce notebook permet d'entra√Æner notre mod√®le de classification des tickets sur Google Colab en utilisant le GPU pour de meilleures performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b02ff91",
   "metadata": {
    "id": "1b02ff91"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "except ImportError:\n",
    "    raise RuntimeError(\"Ce notebook doit √™tre ex√©cut√© dans Google Colab. Veuillez l'ouvrir avec : https://colab.research.google.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee579677",
   "metadata": {
    "id": "ee579677"
   },
   "source": [
    "## 1. Configuration de Google Drive\n",
    "\n",
    "Premi√®rement, nous allons connecter Google Drive pour acc√©der √† nos donn√©es et sauvegarder nos mod√®les."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1ac51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06f1ac51",
    "outputId": "81f5077a-159f-4a36-84b8-3f262bc739a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Cr√©er les dossiers n√©cessaires\n",
    "!mkdir -p /content/drive/MyDrive/CallCenter/data\n",
    "!mkdir -p /content/drive/MyDrive/CallCenter/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f480063d",
   "metadata": {
    "id": "f480063d"
   },
   "source": [
    "## 2. V√©rification du GPU\n",
    "\n",
    "V√©rifions que nous avons bien acc√®s au GPU sur Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8a562",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82e8a562",
    "outputId": "81407ba6-4e5b-4af9-f5ea-92727bddcfe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible: True\n",
      "Nom du GPU: Tesla T4\n",
      "M√©moire totale (Go): 15.828320256\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# V√©rifier si le GPU est disponible\n",
    "print(\"GPU disponible:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Nom du GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(\"M√©moire totale (Go):\", torch.cuda.get_device_properties(0).total_memory / 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b422f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51b422f7",
    "outputId": "cfabc589-e0b8-47bd-c68b-27dc50c2e269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version CUDA: 12.6\n",
      "Nombre de GPUs disponibles: 1\n",
      "\n",
      "M√©moire GPU:\n",
      "!nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "# V√©rification de CUDA\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Version CUDA:\", torch.version.cuda)\n",
    "    print(\"Nombre de GPUs disponibles:\", torch.cuda.device_count())\n",
    "    # Afficher les informations sur la m√©moire GPU\n",
    "    print(\"\\nM√©moire GPU:\")\n",
    "    print(\"!nvidia-smi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee4dc15",
   "metadata": {
    "id": "5ee4dc15"
   },
   "source": [
    "## 3. Installation des d√©pendances\n",
    "\n",
    "Installons les packages n√©cessaires pour l'entra√Ænement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a73fd39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7a73fd39",
    "outputId": "1ec8600d-026c-49bf-e387-30b293c03d7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m124.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m752.6/752.6 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Installation des packages\n",
    "!pip install transformers datasets evaluate scikit-learn pandas numpy mlflow --quiet\n",
    "!pip install accelerate -U --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee20800",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ee20800",
    "outputId": "91735cb3-fd26-4bb1-e9f0-1f897d712b81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers version: 4.57.1\n",
      "datasets version: 4.0.0\n",
      "pandas version: 2.2.2\n",
      "torch version: 2.8.0+cu126\n"
     ]
    }
   ],
   "source": [
    "# V√©rifier les versions install√©es\n",
    "import transformers\n",
    "import datasets\n",
    "import pandas\n",
    "import torch\n",
    "\n",
    "print(\"transformers version:\", transformers.__version__)\n",
    "print(\"datasets version:\", datasets.__version__)\n",
    "print(\"pandas version:\", pandas.__version__)\n",
    "print(\"torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32473b02",
   "metadata": {
    "id": "32473b02"
   },
   "source": [
    "## 4. Chargement et pr√©paration des donn√©es\n",
    "\n",
    "Copions les donn√©es n√©cessaires depuis notre projet local vers Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33165b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420,
     "referenced_widgets": [
      "a016e088b27a41e28c53cd1ca77e5886",
      "9baad1c2612e49a39e006935d226877b",
      "8a5457ca2c5b4a23b7a17d54fee1a2d7",
      "73a3b56da52f490dba27eef6dd716ea2",
      "b4eb0133ccae4c03bda8cb46984ba9c1",
      "139b4d1326b449f78d8a50a5329567c0",
      "5a00a6d477784a96aa3bdae67a2713fd",
      "fa4d8c88aaae49feb96c4d92a4e61c1f",
      "833665cb5b5642f9994a9dc1cd4ae4f2",
      "7fc6c9dd64a8449589397eca2f998b35",
      "1716586229cd419e872eccf513cb2dc2",
      "4ab7c6207d3f45708bd2b174b2610604",
      "1f71968c602949f39abe8ab15be22077",
      "265bf64d063845689c77173484306eb2",
      "84aace6df6cb46f88ed0d67bf6782fb9",
      "59b3be0985af4173868d52a2634037cc",
      "0a65fc3a6ad8408bbc83e7c09a667882",
      "84096fdc5a624a77836f6d8c376b52fe",
      "b3e79fdd20ba488b9f301655589860ce",
      "3048a084342f4a9da11b569e3a510f83",
      "e22dfd3f39b84ff582d59e79716b6ad9",
      "c84e5621ccd149238565be4eac566c83"
     ]
    },
    "id": "b33165b1",
    "outputId": "a049c257-1de4-4dcb-f19e-1f93a9778a88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des donn√©es depuis: /content/drive/MyDrive/CallCenter/data/processed/tickets_clean.csv\n",
      "Nombre total d'√©chantillons charg√©s : 47834\n",
      "Nombre d'√©chantillons apr√®s nettoyage : 47834\n",
      "\n",
      "Nombre de classes : 8\n",
      "Classes disponibles : ['Hardware' 'Access' 'Miscellaneous' 'HR Support' 'Purchase'\n",
      " 'Administrative rights' 'Storage' 'Internal Project']\n",
      "\n",
      "Split des donn√©es :\n",
      "- Ensemble d'entra√Ænement : 38267 √©chantillons\n",
      "- Ensemble de test : 9567 √©chantillons\n",
      "\n",
      "Chargement du tokenizer...\n",
      "\n",
      "Cr√©ation des datasets...\n",
      "Tokenisation des donn√©es...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a016e088b27a41e28c53cd1ca77e5886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38267 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab7c6207d3f45708bd2b174b2610604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9567 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pr√©paration des donn√©es termin√©e !\n"
     ]
    }
   ],
   "source": [
    "# Charger les donn√©es\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "# V√©rifier si le fichier existe dans Google Drive\n",
    "data_path = '/content/drive/MyDrive/CallCenter/data/processed/tickets_clean.csv'\n",
    "if not os.path.exists(data_path):\n",
    "    raise FileNotFoundError(\n",
    "        \"\\nERREUR : Le fichier tickets_clean.csv n'a pas √©t√© trouv√© dans Google Drive.\\n\"\n",
    "        \"Veuillez suivre ces √©tapes :\\n\"\n",
    "        \"1. Assurez-vous d'avoir mont√© Google Drive (ex√©cutez la section 1)\\n\"\n",
    "        \"2. Cr√©ez le dossier : /content/drive/MyDrive/CallCenter/data/\\n\"\n",
    "        \"3. Uploadez votre fichier tickets_clean.csv dans ce dossier\\n\"\n",
    "        \"4. V√©rifiez que le chemin est correct : \" + data_path\n",
    "    )\n",
    "\n",
    "print(\"Chargement des donn√©es depuis:\", data_path)\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"Nombre total d'√©chantillons charg√©s : {len(df)}\")\n",
    "\n",
    "# Nettoyage des donn√©es\n",
    "df = df.dropna(subset=['Document', 'Topic_group'])\n",
    "print(f\"Nombre d'√©chantillons apr√®s nettoyage : {len(df)}\")\n",
    "\n",
    "# Pr√©paration des labels\n",
    "labels = df['Topic_group'].unique()\n",
    "print(f\"\\nNombre de classes : {len(labels)}\")\n",
    "print(\"Classes disponibles :\", labels)\n",
    "\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "df['label'] = df['Topic_group'].map(label2id)\n",
    "\n",
    "# Split train/test\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "print(f\"\\nSplit des donn√©es :\")\n",
    "print(f\"- Ensemble d'entra√Ænement : {len(train_df)} √©chantillons\")\n",
    "print(f\"- Ensemble de test : {len(test_df)} √©chantillons\")\n",
    "\n",
    "# Initialiser le tokenizer\n",
    "print(\"\\nChargement du tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
    "\n",
    "# Fonction de tokenization\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['Document'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "# Cr√©er les datasets HF\n",
    "print(\"\\nCr√©ation des datasets...\")\n",
    "train_dataset = Dataset.from_pandas(train_df[['Document', 'label']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['Document', 'label']])\n",
    "\n",
    "print(\"Tokenisation des donn√©es...\")\n",
    "train_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
    "test_tokenized = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# D√©finir le format pour PyTorch\n",
    "train_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "print(\"\\nPr√©paration des donn√©es termin√©e !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960bfde7",
   "metadata": {
    "id": "960bfde7"
   },
   "source": [
    "## 5. Configuration de l'entra√Ænement avec optimisation m√©moire\n",
    "\n",
    "Configuration du mod√®le et des param√®tres d'entra√Ænement avec les optimisations pour une utilisation efficace du GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d20e9ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7d20e9ae",
    "outputId": "8e22f1c3-a6c3-42ef-e57f-c290d6f4797f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-2922143058.py:63: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Configuration du device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialiser le mod√®le\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-multilingual-cased',\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# Activer le gradient checkpointing pour √©conomiser la m√©moire\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# D√©placer le mod√®le sur GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Fonction de calcul des m√©triques\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.argmax(axis=1)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, predictions),\n",
    "        'f1_macro': f1_score(labels, predictions, average='macro'),\n",
    "        'f1_weighted': f1_score(labels, predictions, average='weighted')\n",
    "    }\n",
    "\n",
    "# Configuration de l'entra√Ænement avec optimisations m√©moire et stockage\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/content/drive/MyDrive/CallCenter/models/best_model',  # Chang√© pour sauvegarder directement dans best_model\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,  # R√©duit de 16 √† 8\n",
    "    per_device_eval_batch_size=8,   # R√©duit de 16 √† 8\n",
    "    gradient_accumulation_steps=4,   # Augment√© de 2 √† 4\n",
    "    num_train_epochs=2,             # R√©duit de 3 √† 2\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1_weighted',\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    report_to='none',\n",
    "    save_total_limit=1,\n",
    "    push_to_hub=False,\n",
    "    overwrite_output_dir=True,\n",
    "    remove_unused_columns=True\n",
    ")\n",
    "\n",
    "# Data collator pour le padding dynamique\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Initialiser le Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5821ae90",
   "metadata": {
    "id": "5821ae90"
   },
   "source": [
    "## 6. Entra√Ænement du mod√®le\n",
    "\n",
    "Lan√ßons l'entra√Ænement avec les optimisations de m√©moire et GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2c95a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3bc2c95a",
    "outputId": "d3da998d-42d9-4a2e-95b5-22dbc311032e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3588' max='3588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3588/3588 48:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.283284</td>\n",
       "      <td>0.597993</td>\n",
       "      <td>0.440001</td>\n",
       "      <td>0.559423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.878258</td>\n",
       "      <td>0.723633</td>\n",
       "      <td>0.671147</td>\n",
       "      <td>0.713505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.667368</td>\n",
       "      <td>0.795338</td>\n",
       "      <td>0.795060</td>\n",
       "      <td>0.794471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.612816</td>\n",
       "      <td>0.804014</td>\n",
       "      <td>0.806465</td>\n",
       "      <td>0.803726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>0.549966</td>\n",
       "      <td>0.822515</td>\n",
       "      <td>0.827770</td>\n",
       "      <td>0.823147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>0.568378</td>\n",
       "      <td>0.814571</td>\n",
       "      <td>0.820149</td>\n",
       "      <td>0.814005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>0.534644</td>\n",
       "      <td>0.820424</td>\n",
       "      <td>0.814376</td>\n",
       "      <td>0.820373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>0.501611</td>\n",
       "      <td>0.837044</td>\n",
       "      <td>0.838475</td>\n",
       "      <td>0.836378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>0.477105</td>\n",
       "      <td>0.839135</td>\n",
       "      <td>0.838776</td>\n",
       "      <td>0.839359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.504900</td>\n",
       "      <td>0.485938</td>\n",
       "      <td>0.842166</td>\n",
       "      <td>0.842407</td>\n",
       "      <td>0.843220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.504900</td>\n",
       "      <td>0.473825</td>\n",
       "      <td>0.842061</td>\n",
       "      <td>0.839194</td>\n",
       "      <td>0.841914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.504900</td>\n",
       "      <td>0.468496</td>\n",
       "      <td>0.846138</td>\n",
       "      <td>0.843881</td>\n",
       "      <td>0.846800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.504900</td>\n",
       "      <td>0.462807</td>\n",
       "      <td>0.844361</td>\n",
       "      <td>0.843418</td>\n",
       "      <td>0.844193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.504900</td>\n",
       "      <td>0.462053</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.846292</td>\n",
       "      <td>0.847343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.466025</td>\n",
       "      <td>0.846765</td>\n",
       "      <td>0.843809</td>\n",
       "      <td>0.847264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.452835</td>\n",
       "      <td>0.849483</td>\n",
       "      <td>0.846946</td>\n",
       "      <td>0.849173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.431448</td>\n",
       "      <td>0.855650</td>\n",
       "      <td>0.853969</td>\n",
       "      <td>0.856063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.439295</td>\n",
       "      <td>0.852305</td>\n",
       "      <td>0.847783</td>\n",
       "      <td>0.852241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.431171</td>\n",
       "      <td>0.857008</td>\n",
       "      <td>0.854747</td>\n",
       "      <td>0.857157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.360700</td>\n",
       "      <td>0.435379</td>\n",
       "      <td>0.854918</td>\n",
       "      <td>0.853736</td>\n",
       "      <td>0.855323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.360700</td>\n",
       "      <td>0.432100</td>\n",
       "      <td>0.857740</td>\n",
       "      <td>0.854578</td>\n",
       "      <td>0.857815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.360700</td>\n",
       "      <td>0.422588</td>\n",
       "      <td>0.860249</td>\n",
       "      <td>0.857760</td>\n",
       "      <td>0.860069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.360700</td>\n",
       "      <td>0.418973</td>\n",
       "      <td>0.861608</td>\n",
       "      <td>0.859014</td>\n",
       "      <td>0.861504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.360700</td>\n",
       "      <td>0.423510</td>\n",
       "      <td>0.859517</td>\n",
       "      <td>0.858562</td>\n",
       "      <td>0.859321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.318100</td>\n",
       "      <td>0.420861</td>\n",
       "      <td>0.859935</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>0.859637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.318100</td>\n",
       "      <td>0.423228</td>\n",
       "      <td>0.860353</td>\n",
       "      <td>0.858132</td>\n",
       "      <td>0.860813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.318100</td>\n",
       "      <td>0.417210</td>\n",
       "      <td>0.862862</td>\n",
       "      <td>0.862092</td>\n",
       "      <td>0.863344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.318100</td>\n",
       "      <td>0.418382</td>\n",
       "      <td>0.859413</td>\n",
       "      <td>0.859347</td>\n",
       "      <td>0.859821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.318100</td>\n",
       "      <td>0.411667</td>\n",
       "      <td>0.861085</td>\n",
       "      <td>0.860271</td>\n",
       "      <td>0.861592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.406286</td>\n",
       "      <td>0.864116</td>\n",
       "      <td>0.862678</td>\n",
       "      <td>0.864198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.407634</td>\n",
       "      <td>0.862653</td>\n",
       "      <td>0.861065</td>\n",
       "      <td>0.862611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.402407</td>\n",
       "      <td>0.865684</td>\n",
       "      <td>0.863682</td>\n",
       "      <td>0.865781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.403982</td>\n",
       "      <td>0.864848</td>\n",
       "      <td>0.862829</td>\n",
       "      <td>0.865046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.408516</td>\n",
       "      <td>0.865161</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.865060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.264200</td>\n",
       "      <td>0.404348</td>\n",
       "      <td>0.865998</td>\n",
       "      <td>0.864347</td>\n",
       "      <td>0.866002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='598' max='598' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [598/598 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R√©sultats de l'√©valuation finale:\n",
      "{'eval_loss': 0.4043479859828949, 'eval_accuracy': 0.8659977004285565, 'eval_f1_macro': 0.8643472774432597, 'eval_f1_weighted': 0.8660024442231926, 'eval_runtime': 13.0537, 'eval_samples_per_second': 732.897, 'eval_steps_per_second': 45.811, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Lib√©rer la m√©moire cache GPU avant l'entra√Ænement\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Lancer l'entra√Ænement\n",
    "trainer.train()\n",
    "\n",
    "# √âvaluation finale\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"\\nR√©sultats de l'√©valuation finale:\")\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd756972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour nettoyer la m√©moire GPU\n",
    "def clear_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"M√©moire GPU nettoy√©e\")\n",
    "        \n",
    "# Nettoyage avant l'entra√Ænement\n",
    "clear_gpu_memory()\n",
    "\n",
    "try:\n",
    "    # Lancer l'entra√Ænement avec gestion d'erreur\n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(f\"\\nErreur pendant l'entra√Ænement : {str(e)}\")\n",
    "    \n",
    "    # Sauvegarder l'√©tat actuel en cas d'erreur\n",
    "    print(\"\\nSauvegarde de secours du mod√®le...\")\n",
    "    trainer.save_model('/content/drive/MyDrive/CallCenter/models/backup_model')\n",
    "    print(\"Mod√®le de secours sauvegard√©!\")\n",
    "\n",
    "# √âvaluation finale\n",
    "print(\"\\n√âvaluation du mod√®le...\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"\\nR√©sultats de l'√©valuation finale:\")\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bca99f",
   "metadata": {
    "id": "a4bca99f"
   },
   "source": [
    "## 7. Sauvegarde du mod√®le\n",
    "\n",
    "Sauvegardons le mod√®le entra√Æn√© sur Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e255b715",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e255b715",
    "outputId": "5d982192-9550-47d5-b9cb-99eb40a92ecc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod√®le sauvegard√© avec succ√®s dans Google Drive !\n"
     ]
    }
   ],
   "source": [
    "# Chemin de sauvegarde sur Google Drive\n",
    "save_path = '/content/drive/MyDrive/CallCenter/models/best_model'\n",
    "\n",
    "# Sauvegarder le mod√®le et le tokenizer\n",
    "trainer.save_model(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "# Sauvegarder les mappings label2id et id2label\n",
    "import json\n",
    "with open(f'{save_path}/label_mappings.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'label2id': label2id,\n",
    "        'id2label': id2label\n",
    "    }, f, indent=2)\n",
    "\n",
    "# ‚≠ê FORCER LA CR√âATION DU FICHIER pytorch_model.bin\n",
    "import torch\n",
    "import os\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "print(\"\\n=== V√©rification et cr√©ation du pytorch_model.bin ===\")\n",
    "\n",
    "# V√©rifier si le fichier existe d√©j√†\n",
    "pytorch_model_path = os.path.join(save_path, 'pytorch_model.bin')\n",
    "\n",
    "if not os.path.exists(pytorch_model_path):\n",
    "    print(\"‚ö†Ô∏è  Le fichier pytorch_model.bin n'existe pas, cr√©ation en cours...\")\n",
    "    \n",
    "    # R√©cup√©rer le mod√®le depuis le trainer\n",
    "    model = trainer.model\n",
    "    \n",
    "    # G√©rer les mod√®les envelopp√©s (DataParallel, DistributedDataParallel)\n",
    "    if hasattr(model, 'module'):\n",
    "        model_to_save = model.module\n",
    "    else:\n",
    "        model_to_save = model\n",
    "    \n",
    "    # D√©placer sur CPU pour √©viter les probl√®mes m√©moire\n",
    "    model_to_save = model_to_save.to('cpu')\n",
    "    \n",
    "    # Sauvegarder le state_dict\n",
    "    torch.save(model_to_save.state_dict(), pytorch_model_path)\n",
    "    print(f\"‚úÖ Fichier pytorch_model.bin cr√©√© avec succ√®s !\")\n",
    "    print(f\"   Taille : {os.path.getsize(pytorch_model_path) / (1024*1024):.2f} MB\")\n",
    "else:\n",
    "    size_mb = os.path.getsize(pytorch_model_path) / (1024*1024)\n",
    "    print(f\"‚úÖ Le fichier pytorch_model.bin existe d√©j√† ! Taille : {size_mb:.2f} MB\")\n",
    "\n",
    "# V√©rifier la structure compl√®te du dossier\n",
    "print(\"\\nüìÅ Fichiers dans le dossier de sauvegarde :\")\n",
    "for f in sorted(os.listdir(save_path)):\n",
    "    filepath = os.path.join(save_path, f)\n",
    "    if os.path.isfile(filepath):\n",
    "        size = os.path.getsize(filepath) / (1024*1024)\n",
    "        print(f\"   - {f} ({size:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"   - {f}/ (dossier)\")\n",
    "\n",
    "print(\"\\n‚úÖ Mod√®le sauvegard√© avec succ√®s dans Google Drive !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08185f1b",
   "metadata": {
    "id": "08185f1b"
   },
   "source": [
    "**Note:** If you encounter a `NameError: name 'trainer' is not defined` when saving the model, ensure that you have executed the \"6. Entra√Ænement du mod√®le\" section first. The `trainer` object is created in that section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923945cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚≠ê DIAGNOSTIC ET R√âPARATION - Ex√©cuter SI pytorch_model.bin est manquant\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_path = '/content/drive/MyDrive/CallCenter/models/best_model/pytorch_model.bin'\n",
    "save_path = '/content/drive/MyDrive/CallCenter/models/best_model'\n",
    "\n",
    "print(\"=== V√âRIFICATION DU MOD√àLE ===\\n\")\n",
    "\n",
    "# 1. V√©rifier l'existence du fichier\n",
    "if os.path.exists(model_path):\n",
    "    size_mb = os.path.getsize(model_path) / (1024 * 1024)\n",
    "    print(f\"‚úÖ Le fichier pytorch_model.bin existe ! Taille : {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(\"‚ùå ERREUR : Le fichier pytorch_model.bin n'existe pas !\")\n",
    "    print(\"\\nüîß R√âPARATION EN COURS...\\n\")\n",
    "    \n",
    "    # 2. V√©rifier ce qui existe dans le dossier\n",
    "    print(\"Fichiers trouv√©s dans le dossier :\")\n",
    "    files = os.listdir(save_path)\n",
    "    for f in sorted(files):\n",
    "        print(f\"   - {f}\")\n",
    "    \n",
    "    # 3. Tenter de charger le mod√®le depuis la configuration\n",
    "    try:\n",
    "        print(\"\\nüì• Tentative de chargement du mod√®le depuis les fichiers existants...\")\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(save_path, local_files_only=True)\n",
    "        print(\"‚úÖ Mod√®le charg√© avec succ√®s !\")\n",
    "        \n",
    "        # 4. Sauvegarder en format unique\n",
    "        print(\"\\nüíæ Sauvegarde en fichier unique...\")\n",
    "        model = model.to('cpu')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"‚úÖ Fichier pytorch_model.bin cr√©√© ! Taille : {os.path.getsize(model_path) / (1024*1024):.2f} MB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Erreur : {str(e)}\")\n",
    "        print(\"\\nüí° SOLUTIONS :\")\n",
    "        print(\"   1. V√©rifiez que trainer.save_model() a bien √©t√© ex√©cut√©\")\n",
    "        print(\"   2. V√©rifiez la sauvegarde dans Google Drive √† ce chemin :\")\n",
    "        print(f\"      {save_path}\")\n",
    "        print(\"   3. Sinon, r√©-ex√©cutez la cellule de sauvegarde (section 7)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63ee447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ TEST DE CHARGEMENT - V√©rifier que le mod√®le fonctionne\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "save_path = '/content/drive/MyDrive/CallCenter/models/best_model'\n",
    "\n",
    "print(\"üîÑ Chargement du mod√®le depuis Google Drive...\\n\")\n",
    "\n",
    "try:\n",
    "    # Charger le mod√®le et le tokenizer\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(save_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(save_path)\n",
    "    \n",
    "    print(\"‚úÖ Mod√®le charg√© avec succ√®s !\")\n",
    "    print(f\"   Type : {model.__class__.__name__}\")\n",
    "    print(f\"   Nombre de param√®tres : {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M\")\n",
    "    \n",
    "    # Test rapide de pr√©diction\n",
    "    print(\"\\nüß™ Test rapide de pr√©diction...\")\n",
    "    test_text = \"Mon probl√®me est r√©solu\"\n",
    "    \n",
    "    inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "    outputs = model(**inputs)\n",
    "    predictions = outputs.logits.argmax(-1)\n",
    "    \n",
    "    print(f\"   Texte : '{test_text}'\")\n",
    "    print(f\"   Classe pr√©dite : {predictions.item()}\")\n",
    "    print(\"\\n‚úÖ Le mod√®le fonctionne correctement !\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur lors du chargement : {str(e)}\")\n",
    "    print(\"\\nüí° Assurez-vous que pytorch_model.bin existe dans le dossier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf53d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell √† coller dans Colab (ex√©cuter APRES l'entra√Ænement)\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/CallCenter/models/best_model\"\n",
    "\n",
    "print(\"=== Listing du dossier de sauvegarde ===\")\n",
    "if os.path.exists(save_path):\n",
    "    for f in sorted(os.listdir(save_path)):\n",
    "        print(f)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Le dossier {save_path} n'existe pas. V√©rifiez le chemin ou sauvegardez d'abord le mod√®le.\")\n",
    "\n",
    "# D√©tecter formats courants\n",
    "files = os.listdir(save_path)\n",
    "has_safetensors = any(f.endswith(\".safetensors\") for f in files)\n",
    "has_single_bin = \"pytorch_model.bin\" in files\n",
    "has_index = \"pytorch_model.bin.index.json\" in files\n",
    "shards = [f for f in files if f.startswith(\"pytorch_model\") and f.endswith(\".bin\") and f != \"pytorch_model.bin\"]\n",
    "\n",
    "print(\"\\nDetections:\")\n",
    "print(\" - safetensors:\", has_safetensors)\n",
    "print(\" - pytorch_model.bin exists:\", has_single_bin)\n",
    "print(\" - sharded index json:\", has_index)\n",
    "print(\" - shards count:\", len(shards))\n",
    "\n",
    "if has_single_bin or has_safetensors:\n",
    "    print(\"\\nUn fichier de poids unique est d√©j√† pr√©sent. Vous pouvez charger le mod√®le avec:\")\n",
    "    print(f\"AutoModelForSequenceClassification.from_pretrained('{save_path}')\")\n",
    "else:\n",
    "    print(\"\\nAucun fichier unique trouv√©. On va tenter de forcer la cr√©ation d'un fichier 'pytorch_model.bin' unique.\")\n",
    "    # R√©cup√©rer l'objet mod√®le depuis trainer si possible, sinon recharger depuis le dossier (attention m√©moire)\n",
    "    try:\n",
    "        model = trainer.model  # si trainer d√©fini dans le notebook\n",
    "        print(\" - Mod√®le r√©cup√©r√© depuis 'trainer.model'.\")\n",
    "    except NameError:\n",
    "        model = None\n",
    "        print(\" - 'trainer' non trouv√© en scope. On va essayer de recharger depuis le dossier (peut demander beaucoup de RAM).\")\n",
    "\n",
    "    # Si on ne peut pas r√©cup√©rer trainer.model, on tente from_pretrained (transformers va merger les shards automatiquement si possible)\n",
    "    if model is None:\n",
    "        try:\n",
    "            print(\" - Tentative de rechargement depuis le dossier (AutoModelForSequenceClassification.from_pretrained).\")\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(save_path, local_files_only=False)\n",
    "            print(\" - Rechargement OK.\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"Impossible de recharger le mod√®le depuis le dossier. Message d'erreur: \" + str(e))\n",
    "\n",
    "    # G√©rer les mod√®les distribu√©s/DP\n",
    "    if hasattr(model, \"module\"):\n",
    "        print(\" - D√©tect√© model.module (wrapped). On prend .module\")\n",
    "        model_to_save = model.module\n",
    "    else:\n",
    "        model_to_save = model\n",
    "\n",
    "    # Move to CPU pour sauver (s√©curise la m√©moire GPU)\n",
    "    device_before = next(model_to_save.parameters()).device\n",
    "    try:\n",
    "        model_to_save.to(\"cpu\")\n",
    "    except Exception as e:\n",
    "        print(\" - Warning: impossible de d√©placer le mod√®le sur CPU:\", e)\n",
    "\n",
    "    # Sauvegarder state_dict en un seul fichier\n",
    "    target_file = os.path.join(save_path, \"pytorch_model.bin\")\n",
    "    print(f\"\\nSauvegarde de state_dict dans: {target_file}\")\n",
    "    try:\n",
    "        torch.save(model_to_save.state_dict(), target_file)\n",
    "        print(\" - Sauvegarde r√©ussie.\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\"Erreur lors de torch.save: \" + str(e))\n",
    "    finally:\n",
    "        # remettre sur l'appareil d'origine si possible\n",
    "        try:\n",
    "            model_to_save.to(device_before)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    print(\"\\nListe finale des fichiers:\")\n",
    "    for f in sorted(os.listdir(save_path)):\n",
    "        print(f)\n",
    "\n",
    "    print(\"\\nVous pouvez maintenant charger avec:\\nAutoModelForSequenceClassification.from_pretrained('{}')\".format(save_path))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a65fc3a6ad8408bbc83e7c09a667882": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "139b4d1326b449f78d8a50a5329567c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1716586229cd419e872eccf513cb2dc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f71968c602949f39abe8ab15be22077": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a65fc3a6ad8408bbc83e7c09a667882",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_84096fdc5a624a77836f6d8c376b52fe",
      "value": "Map:‚Äá100%"
     }
    },
    "265bf64d063845689c77173484306eb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3e79fdd20ba488b9f301655589860ce",
      "max": 9567,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3048a084342f4a9da11b569e3a510f83",
      "value": 9567
     }
    },
    "3048a084342f4a9da11b569e3a510f83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4ab7c6207d3f45708bd2b174b2610604": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f71968c602949f39abe8ab15be22077",
       "IPY_MODEL_265bf64d063845689c77173484306eb2",
       "IPY_MODEL_84aace6df6cb46f88ed0d67bf6782fb9"
      ],
      "layout": "IPY_MODEL_59b3be0985af4173868d52a2634037cc"
     }
    },
    "59b3be0985af4173868d52a2634037cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a00a6d477784a96aa3bdae67a2713fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73a3b56da52f490dba27eef6dd716ea2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7fc6c9dd64a8449589397eca2f998b35",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1716586229cd419e872eccf513cb2dc2",
      "value": "‚Äá38267/38267‚Äá[00:18&lt;00:00,‚Äá1906.29‚Äáexamples/s]"
     }
    },
    "7fc6c9dd64a8449589397eca2f998b35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "833665cb5b5642f9994a9dc1cd4ae4f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "84096fdc5a624a77836f6d8c376b52fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84aace6df6cb46f88ed0d67bf6782fb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e22dfd3f39b84ff582d59e79716b6ad9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c84e5621ccd149238565be4eac566c83",
      "value": "‚Äá9567/9567‚Äá[00:03&lt;00:00,‚Äá2767.33‚Äáexamples/s]"
     }
    },
    "8a5457ca2c5b4a23b7a17d54fee1a2d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa4d8c88aaae49feb96c4d92a4e61c1f",
      "max": 38267,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_833665cb5b5642f9994a9dc1cd4ae4f2",
      "value": 38267
     }
    },
    "9baad1c2612e49a39e006935d226877b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_139b4d1326b449f78d8a50a5329567c0",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5a00a6d477784a96aa3bdae67a2713fd",
      "value": "Map:‚Äá100%"
     }
    },
    "a016e088b27a41e28c53cd1ca77e5886": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9baad1c2612e49a39e006935d226877b",
       "IPY_MODEL_8a5457ca2c5b4a23b7a17d54fee1a2d7",
       "IPY_MODEL_73a3b56da52f490dba27eef6dd716ea2"
      ],
      "layout": "IPY_MODEL_b4eb0133ccae4c03bda8cb46984ba9c1"
     }
    },
    "b3e79fdd20ba488b9f301655589860ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4eb0133ccae4c03bda8cb46984ba9c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c84e5621ccd149238565be4eac566c83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e22dfd3f39b84ff582d59e79716b6ad9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa4d8c88aaae49feb96c4d92a4e61c1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
