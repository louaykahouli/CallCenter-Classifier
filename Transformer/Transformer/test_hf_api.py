"""
Script pour tester l'API Hugging Face apr√®s d√©ploiement
Usage: python test_hf_api.py
"""

import requests
import json
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# Configuration
HF_USERNAME = "louaykahouli"  # Votre username
MODEL_NAME = "callcenter-ticket-classifier"
REPO_ID = f"{HF_USERNAME}/{MODEL_NAME}"

# Exemples de tickets √† tester
TEST_TICKETS = [
    "Mon ordinateur portable ne s'allume plus, l'√©cran reste noir",
    "Je n'arrive pas √† me connecter au VPN de l'entreprise",
    "J'ai besoin d'acheter de nouvelles licences Office pour mon √©quipe",
    "Le serveur de fichiers est tr√®s lent aujourd'hui",
    "Je voudrais prendre mes cong√©s la semaine prochaine",
]

def test_with_api(hf_token=None):
    """Teste le mod√®le via l'API Inference de Hugging Face"""
    print("üî• Test via API Inference de Hugging Face")
    print("=" * 60)
    
    if not hf_token:
        print("‚ö†Ô∏è  Pas de token fourni, tentative sans authentification...")
        print("Note : Vous pouvez obtenir un token sur https://huggingface.co/settings/tokens\n")
    
    API_URL = f"https://api-inference.huggingface.co/models/{REPO_ID}"
    headers = {"Authorization": f"Bearer {hf_token}"} if hf_token else {}
    
    for i, ticket in enumerate(TEST_TICKETS, 1):
        print(f"\nüìã Ticket {i} : {ticket}")
        
        try:
            response = requests.post(
                API_URL,
                headers=headers,
                json={"inputs": ticket}
            )
            
            if response.status_code == 200:
                result = response.json()
                print(f"‚úÖ R√©sultat : {json.dumps(result[0] if isinstance(result, list) else result, indent=2)}")
            else:
                print(f"‚ùå Erreur {response.status_code}: {response.text}")
                
        except Exception as e:
            print(f"‚ùå Erreur : {e}")

def test_with_transformers():
    """Teste le mod√®le en le chargeant directement avec transformers"""
    print("\n\nü§ó Test via chargement direct du mod√®le")
    print("=" * 60)
    print(f"Chargement du mod√®le {REPO_ID}...\n")
    
    try:
        # Charger le mod√®le et le tokenizer
        tokenizer = AutoTokenizer.from_pretrained(REPO_ID)
        model = AutoModelForSequenceClassification.from_pretrained(REPO_ID)
        model.eval()
        
        print("‚úÖ Mod√®le charg√© avec succ√®s!\n")
        
        # Tester chaque ticket
        for i, ticket in enumerate(TEST_TICKETS, 1):
            print(f"üìã Ticket {i} : {ticket}")
            
            # Tokenizer
            inputs = tokenizer(
                ticket,
                return_tensors="pt",
                truncation=True,
                max_length=128,
                padding=True
            )
            
            # Pr√©diction
            with torch.no_grad():
                outputs = model(**inputs)
                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
                predicted_class = torch.argmax(predictions, dim=-1).item()
                confidence = predictions[0][predicted_class].item()
            
            print(f"‚úÖ Cat√©gorie pr√©dite : {predicted_class}")
            print(f"   Confiance : {confidence:.2%}\n")
            
    except Exception as e:
        print(f"‚ùå Erreur : {e}")
        print("\nüí° Si le mod√®le n'est pas trouv√©, assurez-vous de l'avoir d√©ploy√© avec :")
        print("   python deploy_to_huggingface.py")

if __name__ == "__main__":
    print("üéØ Test du mod√®le CallCenter sur Hugging Face")
    print("=" * 60)
    print(f"Mod√®le : {REPO_ID}\n")
    
    # Option 1 : Test avec l'API
    hf_token = input("Entrez votre token Hugging Face (ou appuyez sur Entr√©e pour passer) : ").strip()
    if hf_token:
        test_with_api(hf_token)
    else:
        print("‚è≠Ô∏è  Test API ignor√© (pas de token)\n")
    
    # Option 2 : Test en chargeant le mod√®le
    print("\n" + "=" * 60)
    response = input("Voulez-vous tester en chargeant le mod√®le localement ? (o/n) : ").strip().lower()
    if response == 'o':
        test_with_transformers()
    
    print("\n‚úÖ Tests termin√©s!")
